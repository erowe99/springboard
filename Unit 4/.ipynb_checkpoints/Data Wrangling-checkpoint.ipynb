{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pendulum\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Wrangling Section 1: Assessment Page Views.csv\n",
    "\"\"\"\n",
    "#Read in csv as dataframe\n",
    "#Using a smaller subset of the data since testing with 6mil+ rows would be too intensive\n",
    "df = pd.read_csv('/Users/ethanrowe/Dev/springboard_data/KSU Assessment Page Views Fall 2018.csv', nrows = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminate Outliers using the 1.5*interquartile rule\n",
    "IQR = float(df['duration'].quantile([0.75])) - float(df['duration'].quantile([0.25]))\n",
    "upper_bound = float(df['duration'].quantile([0.75])) + 1.5*IQR\n",
    "lower_bound = float(df['duration'].quantile([0.25])) - 1.5*IQR\n",
    "\n",
    "df_clean = df[(df['duration'] < upper_bound) & (df['duration'] > lower_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data:\n",
      "(8846, 13)\n",
      "assessment_attempt_id                                         0\n",
      "assessment_type                                               0\n",
      "canvas_assignment_id                                          0\n",
      "canvas_course_id                                              0\n",
      "canvas_section_id                                             0\n",
      "created_at                                                    0\n",
      "duration                                                      0\n",
      "id                                                            0\n",
      "load_time                                                     0\n",
      "page_id                                                       0\n",
      "raw_lti_param_ext_outcome_submission_submitted_at_accepted    0\n",
      "submit_time                                                   0\n",
      "user_param_external_user_id                                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaned Data:\")\n",
    "print(df_clean.shape)\n",
    "print(df.isna().sum())\n",
    "#df_clean.to_csv('KSU Assessment Page Views Fall 2018 Clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouped by Assignment\n",
      "(580, 1)\n",
      "\n",
      "Grouped by User\n",
      "(1865, 1)\n"
     ]
    }
   ],
   "source": [
    "#Group by page and by students to compare average assignment durations\n",
    "assignment_df = pd.DataFrame(df_clean.groupby(['canvas_assignment_id'])['duration'].mean())\n",
    "print('\\nGrouped by Assignment')\n",
    "assignment_df.columns = ['Average Duration']\n",
    "print(assignmnet_df.shape)\n",
    "\n",
    "user_df = pd.DataFrame(df_clean.groupby(['user_param_external_user_id', 'canvas_assignment_id'])['duration'].mean())\n",
    "print('\\nGrouped by User')\n",
    "user_df.columns = ['Average Duration']\n",
    "print(user_df.shape)\n",
    "\n",
    "\n",
    "#page_df.to_csv('KSU Assessment Assignment Duration Averages.csv')\n",
    "#user_df.to_csv('KSU Assessment Student Views by User.csv')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#User_df is good for visualizing the data, but a df that is easier to work with will be labeled sub_df. It has the \n",
    "#same columns as user_df, just in a different order with a numerical index. It will also be sorted by \n",
    "#canvas_assignment_id in order to match assignment_df's index\n",
    "sub_df = user_df.reset_index()  \n",
    "sub_df = sub_df.set_index('canvas_assignment_id')  \n",
    "sub_df = sub_df.sort_index()     \n",
    "sub_df = sub_df.reset_index()    \n",
    "\n",
    "#Using the user_df, turn it back into a dictionary grouped by canvas_assignment ids\n",
    "dfs = {}       \n",
    "for entry in sub_df.iterrows():  \n",
    "    if index != entry[1]['canvas_assignment_id']:  \n",
    "        index = entry[1]['canvas_assignment_id']  \n",
    "        df = pd.DataFrame(columns=['canvas_assignment_id', 'user_param_external_user_id', 'Average Duration'])  \n",
    "        df = df.append(dict(entry[1]), ignore_index = True) \n",
    "        dfs[index] = df  \n",
    "    else:  \n",
    "        dfs[index] = dfs[index].append(dict(entry[1]), ignore_index = True)  \n",
    "\n",
    "#Now page_df and this dictionary dfs should have one to one matches for the loop below\n",
    "#This loop will find all the student-assignment_id pairs that had an above average duration for that assignment\n",
    "above_avg_df = pd.DataFrame(columns = ['canvas_assignment_id', 'user_param_external_user_id','Average Duration']) \n",
    "for entry in assignment_df.iterrows(): \n",
    "    df = dfs[entry[0]] \n",
    "    above_avg_chunk = df[df['Average Duration'] >= entry[1][0]] \n",
    "    above_avg_df = above_avg_df.append(above_avg_chunk) \n",
    "#above_avg_df.to_csv('KSU Students with Above Average Assignment Duration.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Students with longer than average assignmnet durations:\n",
      "(1018, 3)\n",
      "   canvas_assignment_id  user_param_external_user_id  Average Duration\n",
      "0               40876.0                      37827.0      12831.500000\n",
      "0               40878.0                      37949.0       9549.583333\n",
      "3               40878.0                      37251.0      10307.500000\n",
      "0               40879.0                      38399.0      11579.000000\n",
      "5               40879.0                      40394.0      16064.857143\n"
     ]
    }
   ],
   "source": [
    "print(\"Students with longer than average assignmnet durations:\")\n",
    "print(above_avg_df.shape)\n",
    "print(above_avg_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Wrangling Section 2: Course Grades \n",
    "Course Grades has been cleand by hand in excel. The details are outlined in Data Wrangling.md\n",
    "\"\"\"\n",
    "#Import data\n",
    "df2 = pd.read_csv('/Users/ethanrowe/Dev/springboard_data/KSU Student Final Grades 2018 Anonymous.csv', index_col = 0)\n",
    "login_times_clean = pd.read_csv('/Users/ethanrowe/Dev/springboard_data/anon_students_login_times_clean.csv', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   student id  student sis                                            course  \\\n",
      "0       37888          NaN  WELL1000 Foundations for Healthy Living - Howton   \n",
      "1       37902          NaN  WELL1000 Foundations for Healthy Living - Howton   \n",
      "2       37956          NaN  WELL1000 Foundations for Healthy Living - Howton   \n",
      "3       38080          NaN  WELL1000 Foundations for Healthy Living - Howton   \n",
      "4       38176          NaN  WELL1000 Foundations for Healthy Living - Howton   \n",
      "\n",
      "   course id  course sis       section  section id  section sis       term  \\\n",
      "0        622         NaN  WELL 1000/01        1159          NaN  Fall 2018   \n",
      "1        622         NaN  WELL 1000/01        1159          NaN  Fall 2018   \n",
      "2        622         NaN  WELL 1000/01        1159          NaN  Fall 2018   \n",
      "3        622         NaN  WELL 1000/01        1159          NaN  Fall 2018   \n",
      "4        622         NaN  WELL 1000/01        1159          NaN  Fall 2018   \n",
      "\n",
      "   term id  term sis  current score  final score enrollment state  \\\n",
      "0       20       NaN          87.42        86.29           active   \n",
      "1       20       NaN          94.90        93.67           active   \n",
      "2       20       NaN          94.31        93.09           active   \n",
      "3       20       NaN          97.18        95.92           active   \n",
      "4       20       NaN          84.40        83.30           active   \n",
      "\n",
      "   unposted current score  unposted final score  \n",
      "0                   87.42                 86.29  \n",
      "1                   94.90                 93.67  \n",
      "2                   94.31                 93.09  \n",
      "3                   97.18                 95.92  \n",
      "4                   84.40                 83.30  \n",
      "student id                   0\n",
      "student sis               3156\n",
      "course                       0\n",
      "course id                    0\n",
      "course sis                3156\n",
      "section                      0\n",
      "section id                   0\n",
      "section sis               3156\n",
      "term                         0\n",
      "term id                      0\n",
      "term sis                  3156\n",
      "current score                1\n",
      "final score                  0\n",
      "enrollment state             0\n",
      "unposted current score       1\n",
      "unposted final score         0\n",
      "dtype: int64\n",
      "   Course Id  Unposted Final Scores         Login Time  student id\n",
      "0        639                    0.0  Aug 13 at 10:46pm       38094\n",
      "1        659                    0.0  Aug 13 at 11:04am       22168\n",
      "2        659                    0.0   Aug 13 at 3:19pm       37144\n",
      "3        638                    0.0   Aug 13 at 9:04pm       38000\n",
      "4        631                    0.0   Aug 14 at 1:12pm       38410\n"
     ]
    }
   ],
   "source": [
    "#df2 is the same as Course Grades (Final Grade Only View) Fall 2018 but with a column for student names\n",
    "print(df2.head())\n",
    "print(df2.isna().sum() )\n",
    "login_times_clean = login_times_clean.sort_index()\n",
    "print(login_times_clean.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethanrowe/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Theses cell will not run out of order from the rest of the cells since they run permanent changes and use references.\n",
    "\n",
    "#Let's clean this right now\n",
    "login_times_clean.columns = ['course id', 'unposted final score',\n",
    "       'login time', 'student id']\n",
    "\n",
    "#first convert the login column into something that is readable to pd.to_datetime\n",
    "for index, entry in enumerate(login_times_clean['login time']):\n",
    "    login_times_clean['login time'][index] = entry[0:-2] + entry[-2:].upper() + ' 2018'\n",
    "    if login_times_clean['login time'][index][0:4] == 'Sept':\n",
    "        login_times_clean['login time'][index] = 'Sep ' + entry[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert login time new into a datetime object\n",
    "time_format = '%b %d at %H:%M%p %Y'\n",
    "login_times_clean['login time'] = pd.to_datetime(login_times_clean['login time'], format=time_format)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now this data frame is prepped for merging\n",
    "print(login_times_clean.shape)\n",
    "print(login_times_clean.isna().sum())\n",
    "login_times_clean.head()\n",
    "login_times_clean.to_csv('/Users/ethanrowe/Dev/springboard_data/login_times_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "course id                   0\n",
      "unposted final score        0\n",
      "login time                  0\n",
      "student id                  0\n",
      "student sis               490\n",
      "course                      0\n",
      "course sis                490\n",
      "section                     0\n",
      "section id                  0\n",
      "section sis               490\n",
      "term                        0\n",
      "term id                     0\n",
      "term sis                  490\n",
      "current score               0\n",
      "final score                 0\n",
      "enrollment state            0\n",
      "unposted current score      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Merge\n",
    "grades_login_times = pd.merge(login_times_clean, df2, on = ['student id', 'course id', 'unposted final score'], how = 'left')\n",
    "\n",
    "#Now this is EDA ready\n",
    "\n",
    "print(grades_login_times.isna().sum())\n",
    "grades_login_times\n",
    "grades_login_times.to_csv('/Users/ethanrowe/Dev/springboard_data/grades_and_login_times(below 70).csv')\n",
    "\n",
    "#why are there so many NaN values even though each dataframe has no missing values and I think they originally came \n",
    "#from the same dataframe...?\n",
    "#Shit it looks like there are student ids that are not in df2 along with student ids that do not match their course id\n",
    "#in the dataframe, have to figure out who those students are or something. I don't want to deal with that shit right\n",
    "#now though. I should do some EDA on the other dataframe and then come back.\n",
    "#To check maybe I should write code to see if all the student ids from this side are in the other one too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 17)\n",
      "(119, 17)\n"
     ]
    }
   ],
   "source": [
    "#Find the students who stopped being active before the drop date Aug 19\n",
    "drop_date = pd.Timestamp(datetime.date(2018, 8, 20))\n",
    "before_aug = grades_login_times[grades_login_times['login time'] <= drop_date]\n",
    "print(before_aug.shape)\n",
    "\n",
    "#Find the students who stopped being before the other date thing, Oct 3\n",
    "other_date = pd.Timestamp(datetime.date(2018, 10, 4))\n",
    "before_oct = grades_login_times[(grades_login_times['login time'] >= drop_date) & (grades_login_times['login time'] <= other_date)]\n",
    "print(before_oct.shape)\n",
    "\n",
    "\n",
    "#Ask jenn before creating this\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_aug.head()\n",
    "before_aug = before_aug.sort_values('login time')\n",
    "before_aug.to_csv('students_drop_before_aug.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "before_oct.head()\n",
    "before_oct = before_oct.sort_values('login time')\n",
    "before_oct.to_csv('students_drop_before_oct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(326, 17)\n"
     ]
    }
   ],
   "source": [
    "#Find the students who stopped being active before the drop date Aug 19\n",
    "drop_date = pd.Timestamp(datetime.date(2018, 10, 4))\n",
    "full_semester = grades_login_times[grades_login_times['login time'] >= drop_date]\n",
    "print(full_semester.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_semester = full_semester.sort_values('login time')\n",
    "full_semester\n",
    "full_semester.to_csv('/Users/ethanrowe/Dev/springboard_data/grades_and_login_times(below 70 after oct).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOther Data sets to consider are Click History and Assessment Responses\\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Other Data sets to consider are Click History and Assessment Responses\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
